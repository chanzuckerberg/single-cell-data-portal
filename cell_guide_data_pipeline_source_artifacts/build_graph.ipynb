{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee85d2bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/atarashansky/Desktop/czi/single-cell-data-portal\n"
     ]
    }
   ],
   "source": [
    "cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44f3e308",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "* Owlready2 * Warning: optimized Cython parser module 'owlready2_optimized' is not available, defaulting to slower Python implementation\n",
      "\n",
      "Warning: SQLite3 version 3.40.0 and 3.41.2 have huge performance regressions; please install version 3.41.1 or 3.42!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cellxgene_census\n",
    "from backend.wmg.data.rollup import rollup_across_cell_type_descendants\n",
    "import owlready2\n",
    "import json\n",
    "import tiledb\n",
    "from backend.wmg.data.ontology_labels import ontology_term_label, ontology_term_id_labels\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def traverse_with_counting(node):\n",
    "    global traverse_node_counter\n",
    "    global all_unique_nodes\n",
    "    node_count = traverse_node_counter.get(node.name, 0)\n",
    "    traverse_node_counter[node.name] = node_count + 1\n",
    "    all_unique_nodes.add(node.name +\"__\"+str(node_count))\n",
    "    \n",
    "    subclasses = list(node.subclasses())\n",
    "    node_id = node.name.replace('_',':')\n",
    "    if len(subclasses) == 0:\n",
    "        return {\"id\": node.name+\"__\"+str(node_count),\n",
    "                \"name\": id_to_name[node_id] if node_id in id_to_name else node_id,\n",
    "                \"n_cells_rollup\": int(cell_counts_df_rollup[node_id] if node_id in cell_counts_df_rollup else 0),\n",
    "                \"n_cells\": int(cell_counts_df[node_id] if node_id in cell_counts_df else 0),\n",
    "               }\n",
    "        \n",
    "    children = []\n",
    "    for child in subclasses:\n",
    "        children.append(traverse_with_counting(child))\n",
    "\n",
    "    return {\"id\": node.name+\"__\"+str(node_count),\n",
    "                \"name\": id_to_name[node_id] if node_id in id_to_name else node_id,\n",
    "                \"n_cells_rollup\": int(cell_counts_df_rollup[node_id] if node_id in cell_counts_df_rollup else 0),\n",
    "                \"n_cells\": int(cell_counts_df[node_id] if node_id in cell_counts_df else 0),\n",
    "                \"children\": children,\n",
    "               }\n",
    "\n",
    "def _descendants(cell_type):\n",
    "    cell_type_iri = cell_type.replace(\":\", \"_\")\n",
    "    entity = ontology.search_one(iri=f\"http://purl.obolibrary.org/obo/{cell_type_iri}\")\n",
    "    descendants = [i.name.replace(\"_\", \":\") for i in entity.descendants()] if entity else [cell_type]\n",
    "    return descendants\n",
    "\n",
    "def _ancestors(cell_type):\n",
    "    cell_type_iri = cell_type.replace(\":\", \"_\")\n",
    "    entity = ontology.search_one(iri=f\"http://purl.obolibrary.org/obo/{cell_type_iri}\")\n",
    "    ancestors = [i.name.replace(\"_\", \":\") for i in entity.ancestors() if i.name!= \"Thing\"] if entity else [cell_type]\n",
    "    return ancestors\n",
    "\n",
    "def _children(cell_type):\n",
    "    cell_type_iri = cell_type.replace(\":\", \"_\")\n",
    "    entity = ontology.search_one(iri=f\"http://purl.obolibrary.org/obo/{cell_type_iri}\")\n",
    "    children = [i.name.replace(\"_\", \":\") for i in entity.subclasses()] if entity else [cell_type]\n",
    "    return children\n",
    "\n",
    "def _parents(cell_type):\n",
    "    cell_type_iri = cell_type.replace(\":\", \"_\")\n",
    "    entity = ontology.search_one(iri=f\"http://purl.obolibrary.org/obo/{cell_type_iri}\")    \n",
    "    parent_names = [parent.name.replace(\"_\",\":\") for parent in entity.is_a if isinstance(parent, owlready2.ThingClass) and parent.name!= \"Thing\"]\n",
    "    return parent_names\n",
    "\n",
    "def dfs(parents, end, start, node=None, path = None, all_paths = []):\n",
    "    if path is None and node is None:\n",
    "        path = [end]\n",
    "        node = end\n",
    "\n",
    "    if node == start:\n",
    "        return path\n",
    "    \n",
    "    for parent in parents.get(node,[]):\n",
    "        full_path = dfs(parents, end, start, node=parent, path = path+[parent], all_paths=all_paths)\n",
    "        if full_path:\n",
    "            all_paths.append(full_path)\n",
    "            \n",
    "def truncate_graph(graph,valid_nodes):   \n",
    "    if graph['id'] not in valid_nodes:\n",
    "        return False\n",
    "\n",
    "    children= graph.get(\"children\",[])\n",
    "    valid_children = []\n",
    "    append_dummy = False\n",
    "    \n",
    "    invalid_children_ids = []\n",
    "    for child in children:\n",
    "        is_valid = truncate_graph(child, valid_nodes)\n",
    "        if is_valid:\n",
    "            valid_children.append(child)\n",
    "        elif child['id']!='':\n",
    "            invalid_children_ids.append(child['id'])\n",
    "            append_dummy = True\n",
    "\n",
    "    if append_dummy and len(valid_children) > 0:\n",
    "        valid_children.append(\n",
    "            {\"id\": \"\",\n",
    "            \"name\": \"\",\n",
    "            \"n_cells_rollup\": 0,\n",
    "            \"n_cells\": 0,\n",
    "             \"invalid_children_ids\": invalid_children_ids,\n",
    "            \"parent\": graph['id']\n",
    "            }        \n",
    "        )\n",
    "    if len(valid_children) > 0:\n",
    "        graph['children'] = valid_children\n",
    "    else:\n",
    "        if 'children' in graph:\n",
    "            del graph['children']\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "def truncate_graph2(graph, visited_nodes_in_paths):\n",
    "    # i want every node to only show children once\n",
    "    # this means deleting \"children\" if seen more than once\n",
    "    # EXCEPT if one of your children is in a path leading to acinar cell.\n",
    "    # Then, you collapse the remaining children\n",
    "    global nodesWithChildrenFound\n",
    "    if graph['id'].split(\"__\")[0] in nodesWithChildrenFound:\n",
    "        if 'children' in graph:\n",
    "            children = graph['children']            \n",
    "            new_children = []\n",
    "            invalid_children_ids = []\n",
    "            for child in children:\n",
    "                if child['id'] in visited_nodes_in_paths:\n",
    "                    new_children.append(child)\n",
    "                elif child['id'] != '':\n",
    "                    invalid_children_ids.append(child['id'])\n",
    "                    \n",
    "            if len(children) > len(new_children) and len(new_children) > 0:\n",
    "                # append dummy\n",
    "                new_children.append(\n",
    "                    {\"id\": \"\",\n",
    "                    \"name\": \"\",\n",
    "                    \"n_cells_rollup\": 0,\n",
    "                    \"n_cells\": 0,\n",
    "                     \"invalid_children_ids\": invalid_children_ids,\n",
    "                     \"parent\": graph['id']\n",
    "                    }        \n",
    "                )\n",
    "            if len(new_children) > 0:\n",
    "                graph['children'] = new_children\n",
    "            else:\n",
    "                del graph['children']\n",
    "    elif 'children' in graph:\n",
    "        nodesWithChildrenFound.add(graph['id'].split(\"__\")[0])\n",
    "    \n",
    "    \n",
    "    children = graph.get(\"children\",[])\n",
    "    for child in children:\n",
    "        if child['id'] != \"\":\n",
    "            truncate_graph2(child, visited_nodes_in_paths)\n",
    "\n",
    "\n",
    "def prune_node_distinguishers(graph):\n",
    "    graph['id'] = graph['id'].split('__')[0]\n",
    "    for child in graph.get('children',[]):\n",
    "        prune_node_distinguishers(child)\n",
    "\n",
    "def delete_unknown_terms(graph):\n",
    "    new_children = []\n",
    "    for child in graph.get('children',[]):\n",
    "        unknown = child['name'].startswith('CL:')\n",
    "        if not unknown:\n",
    "            new_children.append(child)\n",
    "    if len(new_children) > 0:\n",
    "        graph['children'] = new_children\n",
    "    elif 'children' in graph:\n",
    "        del graph['children']\n",
    "    \n",
    "    for child in graph.get('children',[]):\n",
    "        delete_unknown_terms(child)\n",
    "        \n",
    "def truncate_graph_one_target(graph, target):\n",
    "    global targetFound\n",
    "    if targetFound and graph['id'].split(\"__\")[0] == target.split(\"__\")[0]:\n",
    "        del graph['children']\n",
    "    elif graph['id'] == target:\n",
    "        targetFound = True\n",
    "    \n",
    "    children = graph.get(\"children\",[])\n",
    "    for child in children:\n",
    "        truncate_graph_one_target(child, target)\n",
    "\n",
    "def build_children(graph):\n",
    "    global all_children\n",
    "    children = graph.get('children',[])\n",
    "    if len(children) == 0:\n",
    "        ids = []\n",
    "    else:\n",
    "        ids = [child['id'] for child in children]\n",
    "        \n",
    "    all_children[graph['id']] = ids\n",
    "    \n",
    "    for child in children:\n",
    "        build_children(child)\n",
    "\n",
    "def build_parents(graph):\n",
    "    global all_parents\n",
    "    children = graph.get('children',[])\n",
    "    \n",
    "    for child in children:\n",
    "        all_parents[child['id']]=[graph['id']]\n",
    "        build_parents(child)\n",
    "        \n",
    "def getExpandedData(graph):\n",
    "    global isExpandedNodes\n",
    "    if 'children' in graph:\n",
    "        isExpandedNodes.append(graph['id'])\n",
    "        for child in graph['children']:\n",
    "            getExpandedData(child)\n",
    "                \n",
    "        \n",
    "def getShownData(graph):\n",
    "    global notShownWhenExpandedNodes\n",
    "    \n",
    "    if 'children' in graph:\n",
    "        for child in graph['children']:\n",
    "            if child['id'] == \"\":\n",
    "                if len(child[\"invalid_children_ids\"]) > 0:\n",
    "                    notShownWhenExpandedNodes.append({child['parent']: list(set(child[\"invalid_children_ids\"]))})\n",
    "            else:\n",
    "                getShownData(child)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de757824",
   "metadata": {},
   "source": [
    "# Build ontology tree JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd79ef1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The \"stable\" Census version is not yet available. Using \"latest\" Census version instead.\n",
      "The \"latest\" release is currently 2023-05-15. Specify 'census_version=\"2023-05-15\"' in future calls to open_soma() to ensure data consistency.\n"
     ]
    }
   ],
   "source": [
    "census = cellxgene_census.open_soma()\n",
    "c = census['census_info']['summary_cell_counts'].read().concat().to_pandas()\n",
    "cell_counts_df = c[[i.startswith('CL:') for i in c['ontology_term_id']]].groupby('ontology_term_id').sum(numeric_only=True)[['unique_cell_count']]\n",
    "cell_counts_df['n_cells'] = cell_counts_df['unique_cell_count']\n",
    "del cell_counts_df['unique_cell_count']\n",
    "cell_counts_df['cell_type_ontology_term_id'] = cell_counts_df.index.values\n",
    "cell_counts_df=cell_counts_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc857f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cell_types = [{k: ontology_term_label(k)} for k in ontology_term_id_labels if k.startswith('CL:')]\n",
    "all_cell_types_ids = [list(i.keys())[0] for i in all_cell_types]\n",
    "to_attach = pd.DataFrame()\n",
    "to_attach['cell_type_ontology_term_id']=[i for i in all_cell_types_ids if i not in cell_counts_df['cell_type_ontology_term_id'].values]\n",
    "to_attach['n_cells']=0\n",
    "\n",
    "cell_counts_df = pd.concat([cell_counts_df,to_attach],axis=0)\n",
    "cell_counts_df_rollup = rollup_across_cell_type_descendants(cell_counts_df).set_index('cell_type_ontology_term_id')['n_cells']\n",
    "cell_counts_df = cell_counts_df.set_index('cell_type_ontology_term_id')['n_cells']\n",
    "\n",
    "id_to_name = pd.Series(index=cell_counts_df.index,data=[ontology_term_label(i) for i in cell_counts_df.index])\n",
    "\n",
    "\n",
    "ontology = owlready2.get_ontology(\"https://github.com/obophenotype/cell-ontology/releases/latest/download/cl-basic.owl\")\n",
    "ontology.load()\n",
    "\n",
    "root_node = ontology.world[\"http://purl.obolibrary.org/obo/CL_0000548\"]\n",
    "\n",
    "traverse_node_counter = {}\n",
    "all_unique_nodes = set()\n",
    "a = traverse_with_counting(root_node) \n",
    "all_unique_nodes = list(all_unique_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d83b31b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_children={}\n",
    "all_parents={}    \n",
    "build_children(a)\n",
    "build_parents(a) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ddd9f16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n"
     ]
    }
   ],
   "source": [
    "start_node = 'CL_0000548__0'\n",
    "\n",
    "all_states_per_cell_type = {}\n",
    "for i,end_node in enumerate(all_cell_types_ids):\n",
    "    if i%100==0:\n",
    "        print(i)\n",
    "    end_node = end_node.replace(\":\",\"_\")\n",
    "    if end_node in traverse_node_counter:\n",
    "        all_paths=[]\n",
    "        for i in range(traverse_node_counter[end_node]):\n",
    "            paths = []    \n",
    "            dfs(all_parents,end_node+\"__\"+str(i),start_node,all_paths=paths)\n",
    "            paths = [i[::-1] for i in paths] \n",
    "            if len(paths) == 0:\n",
    "                all_paths.append([end_node+\"__\"+str(i)])\n",
    "            else:\n",
    "                all_paths.append(paths[0])\n",
    "\n",
    "        ### RULES ###\n",
    "        # 1. We only want to show terms that are CHILDREN, GRANDCHILDREN, SIBLINGS OF TARGET, or IN A PATH TO TARGET\n",
    "        visited_nodes_in_paths = list(set(sum(all_paths,[])))\n",
    "\n",
    "        children1 = all_children.get(end_node+\"__0\",[]) #children\n",
    "        children2 = sum([all_children.get(child,[]) for child in children1],[]) #grandchildren\n",
    "        siblings=[]\n",
    "        for i in range(traverse_node_counter[end_node]):\n",
    "            sibs = sum([all_children.get(parent,[]) for parent in all_parents.get(end_node+\"__\"+str(i),[])],[]) #siblings\n",
    "            siblings.append(sibs)\n",
    "        siblings = list(set(sum(siblings,[])))\n",
    "\n",
    "\n",
    "        valid_nodes = list(set(visited_nodes_in_paths + children1 + children2 + siblings))\n",
    "\n",
    "        a_copy = json.loads(json.dumps(a))\n",
    "        truncate_graph(a_copy,valid_nodes) \n",
    "\n",
    "        nodesWithChildrenFound=set()\n",
    "        truncate_graph2(a_copy, visited_nodes_in_paths)\n",
    "        delete_unknown_terms(a_copy)\n",
    "        \n",
    "        # now, given this graph, populate what you need - specifically, we need \"notShownWhenExpanded\" and \"isExpanded\"\n",
    "        notShownWhenExpandedNodes=[]\n",
    "        isExpandedNodes=[]\n",
    "        \n",
    "        getExpandedData(a_copy)\n",
    "        getShownData(a_copy)\n",
    "\n",
    "        assert(len(list(set([list(i.keys())[0] for i in notShownWhenExpandedNodes])))==len(notShownWhenExpandedNodes))        \n",
    "        \n",
    "        notShownWhenExpanded = {}\n",
    "        for i in notShownWhenExpandedNodes:\n",
    "            notShownWhenExpanded.update(i)\n",
    "            \n",
    "        all_states_per_cell_type[end_node] = {'isExpandedNodes': list(set(isExpandedNodes)), 'notShownWhenExpandedNodes': notShownWhenExpanded}  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47ac0685",
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(a,open('ontologyTree.json','w'))\n",
    "json.dump(all_states_per_cell_type,open('allOntologyTreeState.json','w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77ef0d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv ontologyTree.json frontend/src/views/CellCards/common/fixtures/.\n",
    "!mv allOntologyTreeState.json frontend/src/views/CellCards/common/fixtures/."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
