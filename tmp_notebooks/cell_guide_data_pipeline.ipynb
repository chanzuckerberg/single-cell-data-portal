{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a057443",
   "metadata": {},
   "source": [
    "# CellGuide data pipeline prototype\n",
    "\n",
    "This assumes a local snapshot has been downloaded to the same location as this notebook.\n",
    "\n",
    "Here is a one-liner for downloading the latest prod snapshot:\n",
    "\n",
    "```\n",
    "AWS_PROFILE=single-cell-prod aws s3 sync s3://cellxgene-wmg-prod/$(AWS_PROFILE=single-cell-prod aws s3 cp s3://cellxgene-wmg-prod/latest_snapshot_identifier -)/ prod-snapshot/\n",
    "```\n",
    "\n",
    "**This file should be in the root folder of the `single-cell-data-portal` repo**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a600b5f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/atarashansky/czi/single-cell-data-portal\n"
     ]
    }
   ],
   "source": [
    "cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8ed8504",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "* Owlready2 * Warning: optimized Cython parser module 'owlready2_optimized' is not available, defaulting to slower Python implementation\n"
     ]
    }
   ],
   "source": [
    "from backend.wmg.api.v1 import build_filter_dims_values\n",
    "from backend.wmg.data.ontology_labels import ontology_term_label, ontology_term_id_labels\n",
    "from backend.wmg.data.snapshot import WmgSnapshot\n",
    "from backend.wmg.data.query import WmgFiltersQueryCriteria\n",
    "import tiledb\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import openai\n",
    "from backend.wmg.data.utils import get_datasets_from_curation_api, get_collections_from_curation_api\n",
    "from backend.wmg.data.rollup import (\n",
    "    rollup_across_cell_type_descendants,\n",
    "    rollup_across_cell_type_descendants_array,\n",
    "    are_cell_types_colinear,\n",
    "    _descendants,\n",
    ")\n",
    "import glob\n",
    "import requests\n",
    "import itertools\n",
    "from scipy import stats\n",
    "import owlready2\n",
    "from pronto import Ontology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e20b2ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sn = \"prod-snapshot\"\n",
    "snapshot = WmgSnapshot(snapshot_identifier=\"\",\n",
    "    expression_summary_cube=tiledb.open(f'{sn}/expression_summary'),\n",
    "    marker_genes_cube=tiledb.open(f'{sn}/marker_genes'),\n",
    "    expression_summary_default_cube=tiledb.open(f'{sn}/expression_summary_default'),\n",
    "    expression_summary_fmg_cube=tiledb.open(f'{sn}/expression_summary_fmg'),                       \n",
    "    cell_counts_cube=tiledb.open(f'{sn}/cell_counts'),\n",
    "    cell_type_orderings=pd.read_json(f'{sn}/cell_type_orderings.json'),\n",
    "    primary_filter_dimensions=json.load(open(f'{sn}/primary_filter_dimensions.json','r')),\n",
    "    dataset_to_gene_ids=json.load(open(f'{sn}/dataset_to_gene_ids.json','r')), \n",
    "    filter_relationships=json.load(open(f'{sn}/filter_relationships.json','r')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac603523",
   "metadata": {},
   "source": [
    "## Generate all cell types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ee9cdab",
   "metadata": {},
   "outputs": [],
   "source": [
    "ontology = Ontology(\"https://github.com/obophenotype/cell-ontology/releases/latest/download/cl-basic.obo\")\n",
    "\n",
    "\n",
    "all_cell_types = json.load(open('frontend/src/views/CellCards/common/fixtures/allCellTypes.json','r'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e6b389",
   "metadata": {},
   "source": [
    "## Generate cell type descriptions using GPT 3.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e97b2a",
   "metadata": {},
   "source": [
    "System role:\n",
    "> You are a knowledgeable cell biologist that has professional experience writing and curating accurate and informative descriptions of cell types.\n",
    "\n",
    "User role:\n",
    "> I am making a knowledge-base about cell types. Each cell type is a term from the Cell Ontology and will have its own page with a detailed description of that cell type and its function. Please write me a description for \"{cell_type_name}\". Please return only the description and no other dialogue. The description should include information about the cell type's function. The description should be at least three paragraphs long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04d69e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_descs = json.load(open('frontend/src/views/CellCards/common/fixtures/allCellTypeDescriptions.json','r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a4005d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.organization = \"org-4kBCayJVUBGqH42cJhzZYQ6o\"\n",
    "openai.api_key = \"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\"\n",
    "openai.Model.list()\n",
    "\n",
    "def func(cname):\n",
    "    print(cname)\n",
    "    succeeded=False\n",
    "    while not succeeded:\n",
    "        try:\n",
    "            result = openai.ChatCompletion.create(\n",
    "                model=\"gpt-3.5-turbo\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are a knowledgeable cell biologist that has professional experience writing and curating accurate and informative descriptions of cell types.\"},\n",
    "                    {\"role\": \"user\", \"content\": f\"I am making a knowledge-base about cell types. Each cell type is a term from the Cell Ontology and will have its own page with a detailed description of that cell type and its function. Please write me a description for \\\"{cname}\\\". Please return only the description and no other dialogue. The description should include information about the cell type's function. The description should be at least three paragraphs long.\"},\n",
    "                ]\n",
    "            ) \n",
    "            succeeded=True\n",
    "        except:\n",
    "            print(\"Trying again due to RLE\")\n",
    "    return result['choices'][0]['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89fdbd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import concurrent.futures\n",
    "\n",
    "all_cell_type_descriptions = {}\n",
    "z=0\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=100) as executor:\n",
    "    # Start the load operations and mark each future with its URL\n",
    "    futures = {executor.submit(func, cell_type['label']): cell_type['id'] for cell_type in all_cell_types if cell_type['id'] not in current_descs}    \n",
    "\n",
    "    for future in concurrent.futures.as_completed(futures):\n",
    "        cid = futures[future]\n",
    "        \n",
    "        if z%50==0:\n",
    "            print(z)\n",
    "        z+=1\n",
    "        \n",
    "        try:\n",
    "            all_cell_type_descriptions[cid] = data = future.result()\n",
    "        except Exception as e:\n",
    "            pass\n",
    "        \n",
    "all_cell_type_descriptions.update(current_descs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3dc9f4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(all_cell_type_descriptions,open('build_graph_output/allCellTypeDescriptions.json','w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5747676",
   "metadata": {},
   "source": [
    "## Generate source data per cell type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "787609a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: DEPLOYMENT_STAGE=test\n"
     ]
    }
   ],
   "source": [
    "%env DEPLOYMENT_STAGE=test\n",
    "\n",
    "def get_title_from_doi(doi):\n",
    "    url = f\"https://api.crossref.org/works/{doi}\"\n",
    "\n",
    "    # Send a GET request to the API\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # If the GET request is successful, the status code will be 200\n",
    "    if response.status_code == 200:\n",
    "        # Get the response data\n",
    "        data = response.json()\n",
    "\n",
    "        # Get the title and citation count from the data\n",
    "        try:\n",
    "            title = data['message']['title'][0]\n",
    "        except:\n",
    "            try:\n",
    "                title = data['message']['items'][0]['title'][0]\n",
    "            except:\n",
    "                return doi\n",
    "        return title\n",
    "    else:\n",
    "        return doi\n",
    "    \n",
    "def format_citation(metadata):\n",
    "    first_author = metadata['publisher_metadata']['authors'][0]\n",
    "    if \"family\" in first_author:\n",
    "        author_str = f\"{first_author['family']}, {first_author['given']} et al.\"\n",
    "    else:\n",
    "        author_str = f\"{first_author['name']} et al.\"\n",
    "    \n",
    "    journal = metadata['publisher_metadata']['journal']\n",
    "    year = metadata['publisher_metadata']['published_year']\n",
    "    \n",
    "    return f\"{author_str} ({year}) {journal}\"\n",
    "\n",
    "snapshot.build_dataset_metadata_dict()\n",
    "\n",
    "datasets = get_datasets_from_curation_api()\n",
    "collections = get_collections_from_curation_api()\n",
    "\n",
    "collections_dict = {collection['collection_id']: collection for collection in collections}\n",
    "datasets_dict = {dataset['dataset_id']: dataset for dataset in datasets}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "40d0a686",
   "metadata": {},
   "outputs": [],
   "source": [
    "cts = [i['id'] for i in all_cell_types]\n",
    "\n",
    "DATA = {}\n",
    "\n",
    "for i in cts:\n",
    "    seen_datasets = []\n",
    "    lineage =_descendants(i)    \n",
    "    assert i in lineage\n",
    "    datasets=[]\n",
    "    for organism in snapshot.primary_filter_dimensions['tissue_terms']:    \n",
    "        criteria = WmgFiltersQueryCriteria(organism_ontology_term_id=organism,\n",
    "                                           cell_type_ontology_term_ids=lineage)\n",
    "        res = build_filter_dims_values(criteria, snapshot)\n",
    "        data = res['datasets']\n",
    "        for datum in data:\n",
    "            if datum['id'] not in seen_datasets and datum['collection_id']!='':\n",
    "                seen_datasets.append(datum['id'])\n",
    "                datasets.append(datum)\n",
    "\n",
    "    collections_to_datasets = {}\n",
    "    for dataset in datasets:\n",
    "        dataset = datasets_dict[dataset['id']]\n",
    "        \n",
    "        a = collections_to_datasets.get(dataset['collection_id'],{})\n",
    "\n",
    "        a['collection_name'] = collections_dict[dataset['collection_id']]['name']\n",
    "        a['collection_url'] = collections_dict[dataset['collection_id']]['collection_url']\n",
    "        a['publication_url'] = collections_dict[dataset['collection_id']]['doi']\n",
    "        if collections_dict[dataset['collection_id']]['publisher_metadata']:\n",
    "            a['publication_title'] = format_citation(collections_dict[dataset['collection_id']])\n",
    "        else:\n",
    "            a['publication_title'] = \"Publication\"\n",
    "            \n",
    "        tissues = a.get(\"tissue\", [])\n",
    "        diseases = a.get(\"disease\", [])\n",
    "        organisms = a.get(\"organism\", [])\n",
    "        for tissue in dataset['tissue']:\n",
    "            if tissue['ontology_term_id'] not in [i['ontology_term_id'] for i in tissues]:\n",
    "                tissues.append(tissue)\n",
    "            \n",
    "        for disease in dataset['disease']:\n",
    "            if disease['ontology_term_id'] not in [i['ontology_term_id'] for i in diseases]:\n",
    "                diseases.append(disease)\n",
    "            \n",
    "        for organism in dataset['organism']:\n",
    "            if organism['ontology_term_id'] not in [i['ontology_term_id'] for i in organisms]:\n",
    "                organisms.append(organism)\n",
    "            \n",
    "        a['tissue'] = tissues\n",
    "        a['disease'] = diseases\n",
    "        a['organism'] = organisms\n",
    "    \n",
    "        collections_to_datasets[dataset['collection_id']]=a\n",
    "\n",
    "    DATA[i] = list(collections_to_datasets.values())                                 \n",
    "json.dump(DATA,open('build_graph_output/allSourceData.json','w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069bef8e",
   "metadata": {},
   "source": [
    "## Generate enriched genes and expression metrics per cell type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "369a3c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _run_ttest(sum1, sumsq1, n1, sum2, sumsq2, n2):\n",
    "    with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n",
    "        mean1 = sum1 / n1\n",
    "        meansq1 = sumsq1 / n1\n",
    "\n",
    "        mean2 = sum2 / n2\n",
    "        meansq2 = sumsq2 / n2\n",
    "\n",
    "        var1 = meansq1 - mean1**2\n",
    "        var1[var1 < 0] = 0\n",
    "        var2 = meansq2 - mean2**2\n",
    "        var2[var2 < 0] = 0\n",
    "\n",
    "        var1_n = var1 / n1\n",
    "        var2_n = var2 / n2\n",
    "        sum_var_n = var1_n + var2_n\n",
    "        dof = sum_var_n**2 / (var1_n**2 / (n1 - 1) + var2_n**2 / (n2 - 1))\n",
    "        tscores = (mean1 - mean2) / np.sqrt(sum_var_n)\n",
    "        effects = (mean1 - mean2) / np.sqrt(((n1 - 1) * var1 + (n2 - 1) * var2) / (n1 + n2 - 1))\n",
    "\n",
    "    pvals = stats.t.sf(tscores, dof)\n",
    "    return pvals, effects\n",
    "\n",
    "def _post_process_stats(\n",
    "    cell_type_target,\n",
    "    cell_types_context,\n",
    "    genes,\n",
    "    pvals,\n",
    "    effects,\n",
    "    percentile=0.05\n",
    "):\n",
    "    is_colinear = np.array(\n",
    "        [are_cell_types_colinear(cell_type, cell_type_target) for cell_type in cell_types_context]\n",
    "    )\n",
    "    effects[is_colinear] = np.nan\n",
    "    pvals[is_colinear] = np.nan\n",
    "    \n",
    "    # aggregate\n",
    "    effects = np.nanpercentile(effects, percentile * 100, axis=0)\n",
    "    pvals = np.array([stats.combine_pvalues(x[np.invert(np.isnan(x))] + 1e-300)[-1] for x in pvals.T])\n",
    "\n",
    "    markers = np.array(genes)[np.argsort(-effects)]\n",
    "    p = pvals[np.argsort(-effects)]\n",
    "    effects = effects[np.argsort(-effects)]\n",
    "    \n",
    "    statistics = []\n",
    "    final_markers = []\n",
    "    for i in range(len(p)):\n",
    "        pi = p[i]\n",
    "        ei = effects[i]\n",
    "        if ei is not np.nan and pi is not np.nan:\n",
    "            statistics.append({f\"p_value\": pi, f\"effect_size\": ei})\n",
    "            final_markers.append(markers[i])\n",
    "    return dict(zip(list(final_markers), statistics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee82873",
   "metadata": {},
   "outputs": [],
   "source": [
    "organism_id_to_name = {}\n",
    "[organism_id_to_name.update(i) for i in snapshot.primary_filter_dimensions['organism_terms']];\n",
    "\n",
    "cell_counts_df = snapshot.cell_counts_cube.df[:]\n",
    "cell_counts_df = cell_counts_df.groupby(['organism_ontology_term_id','cell_type_ontology_term_id']).sum(numeric_only=True)\n",
    "\n",
    "expressions_df = snapshot.expression_summary_fmg_cube.df[:]\n",
    "expressions_df = expressions_df.groupby(['organism_ontology_term_id','cell_type_ontology_term_id','gene_ontology_term_id']).sum(numeric_only=True)\n",
    "expressions_df = expressions_df.reset_index()\n",
    "\n",
    "all_cell_type_ids = [i['id'] for i in all_cell_types]\n",
    "cell_counts_df = cell_counts_df[cell_counts_df.index.get_level_values('cell_type_ontology_term_id').isin(all_cell_type_ids)]\n",
    "\n",
    "index = pd.Index(list(itertools.product(cell_counts_df.index.get_level_values('organism_ontology_term_id').unique(),all_cell_type_ids)))\n",
    "index = index.set_names(['organism_ontology_term_id','cell_type_ontology_term_id'])\n",
    "universe_cell_counts_df = pd.DataFrame(index = index)\n",
    "universe_cell_counts_df['n_cells']=0\n",
    "universe_cell_counts_df['n_cells'][cell_counts_df.index] = cell_counts_df['n_cells']\n",
    "\n",
    "universe_cell_counts_df = rollup_across_cell_type_descendants(\n",
    "    universe_cell_counts_df.reset_index()\n",
    ")\n",
    "universe_cell_counts_df=universe_cell_counts_df[universe_cell_counts_df['n_cells']>0]\n",
    "universe_cell_counts_df = universe_cell_counts_df.groupby(['organism_ontology_term_id','cell_type_ontology_term_id']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4b0bbe14",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = list(set(list(universe_cell_counts_df.index.get_level_values('cell_type_ontology_term_id'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "88db58a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cell_types = [c for c in all_cell_types if c['id'] in a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "52e75b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(all_cell_types,open('build_graph_output/allCellTypes.json','w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0161691b",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"[('NCBITaxon:10090', 'CL:0000391')] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 36\u001b[0m\n\u001b[1;32m     33\u001b[0m e_sum_rollup \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros_like(e_sum)\n\u001b[1;32m     34\u001b[0m e_sqsum_rollup \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros_like(e_sqsum)\n\u001b[0;32m---> 36\u001b[0m n_cells \u001b[38;5;241m=\u001b[39m \u001b[43muniverse_cell_counts_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mn_cells\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx_index\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     37\u001b[0m n_cells \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mtile(n_cells\u001b[38;5;241m.\u001b[39mvalues[:,\u001b[38;5;28;01mNone\u001b[39;00m],(\u001b[38;5;241m1\u001b[39m,e_nnz_rollup\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]))\n\u001b[1;32m     39\u001b[0m all_results \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/miniconda3/envs/dev/lib/python3.10/site-packages/pandas/core/series.py:1033\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     key \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(key, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mbool\u001b[39m)\n\u001b[1;32m   1031\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_values(key)\n\u001b[0;32m-> 1033\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_with\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dev/lib/python3.10/site-packages/pandas/core/series.py:1073\u001b[0m, in \u001b[0;36mSeries._get_with\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1070\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miloc[key]\n\u001b[1;32m   1072\u001b[0m \u001b[38;5;66;03m# handle the dup indexing case GH#4246\u001b[39;00m\n\u001b[0;32m-> 1073\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dev/lib/python3.10/site-packages/pandas/core/indexing.py:1103\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1100\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   1102\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[0;32m-> 1103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dev/lib/python3.10/site-packages/pandas/core/indexing.py:1332\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1329\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m key\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1330\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot index with multidimensional key\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1332\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_iterable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1334\u001b[0m \u001b[38;5;66;03m# nested tuple slicing\u001b[39;00m\n\u001b[1;32m   1335\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_nested_tuple(key, labels):\n",
      "File \u001b[0;32m~/miniconda3/envs/dev/lib/python3.10/site-packages/pandas/core/indexing.py:1272\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_iterable\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1269\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_key(key, axis)\n\u001b[1;32m   1271\u001b[0m \u001b[38;5;66;03m# A collection of keys\u001b[39;00m\n\u001b[0;32m-> 1272\u001b[0m keyarr, indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_listlike_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1273\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_reindex_with_indexers(\n\u001b[1;32m   1274\u001b[0m     {axis: [keyarr, indexer]}, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, allow_dups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1275\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/dev/lib/python3.10/site-packages/pandas/core/indexing.py:1462\u001b[0m, in \u001b[0;36m_LocIndexer._get_listlike_indexer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1459\u001b[0m ax \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis(axis)\n\u001b[1;32m   1460\u001b[0m axis_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis_name(axis)\n\u001b[0;32m-> 1462\u001b[0m keyarr, indexer \u001b[38;5;241m=\u001b[39m \u001b[43max\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1464\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m keyarr, indexer\n",
      "File \u001b[0;32m~/miniconda3/envs/dev/lib/python3.10/site-packages/pandas/core/indexes/multi.py:2539\u001b[0m, in \u001b[0;36mMultiIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   2536\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_if_missing(key, indexer, axis_name)\n\u001b[1;32m   2537\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[indexer], indexer\n\u001b[0;32m-> 2539\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dev/lib/python3.10/site-packages/pandas/core/indexes/base.py:5876\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   5873\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   5874\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 5876\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5878\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   5879\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   5880\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/dev/lib/python3.10/site-packages/pandas/core/indexes/multi.py:2559\u001b[0m, in \u001b[0;36mMultiIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   2557\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkeyarr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2558\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2559\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dev/lib/python3.10/site-packages/pandas/core/indexes/base.py:5938\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   5935\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   5937\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m-> 5938\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"[('NCBITaxon:10090', 'CL:0000391')] not in index\""
     ]
    }
   ],
   "source": [
    "x = list(zip(*expressions_df[['organism_ontology_term_id','cell_type_ontology_term_id']].values.T))\n",
    "y = list(expressions_df['gene_ontology_term_id'])\n",
    "\n",
    "xu = list(set(x))\n",
    "yu = list(set(y))\n",
    "\n",
    "x_index = pd.Series(index=pd.Index(xu),data=np.arange(len(xu)))\n",
    "y_index = pd.Series(index=pd.Index(yu),data=np.arange(len(yu)))\n",
    "\n",
    "e_nnz = np.zeros((len(xu),len(yu)))\n",
    "e_sum = np.zeros((len(xu),len(yu)))\n",
    "e_sqsum = np.zeros((len(xu),len(yu)))\n",
    "\n",
    "e_nnz[x_index[x].values, y_index[y].values] = expressions_df['nnz']\n",
    "e_sum[x_index[x].values, y_index[y].values] = expressions_df['sum']\n",
    "e_sqsum[x_index[x].values, y_index[y].values] = expressions_df['sqsum']\n",
    "\n",
    "available_combinations = set(list(universe_cell_counts_df.index.values))\n",
    "missing_combinations = available_combinations.difference(xu)\n",
    "\n",
    "xu = xu + list(missing_combinations)\n",
    "x_index = pd.Series(index=pd.Index(xu),data=np.arange(len(xu)))\n",
    "\n",
    "e_nnz = np.vstack((e_nnz,np.zeros((len(missing_combinations),e_nnz.shape[1]))))\n",
    "e_sum = np.vstack((e_sum,np.zeros((len(missing_combinations),e_sum.shape[1]))))\n",
    "e_sqsum = np.vstack((e_sqsum,np.zeros((len(missing_combinations),e_sqsum.shape[1]))))\n",
    "\n",
    "organisms = x_index.index.get_level_values(0)\n",
    "organisms_u = list(set(organisms))\n",
    "cell_types = x_index.index.get_level_values(1)\n",
    "\n",
    "e_nnz_rollup = np.zeros_like(e_nnz)\n",
    "e_sum_rollup = np.zeros_like(e_sum)\n",
    "e_sqsum_rollup = np.zeros_like(e_sqsum)\n",
    "\n",
    "n_cells = universe_cell_counts_df['n_cells'][x_index.index]\n",
    "n_cells = np.tile(n_cells.values[:,None],(1,e_nnz_rollup.shape[1]))\n",
    "\n",
    "all_results = []\n",
    "for organism in organisms_u:\n",
    "    cell_types_o = cell_types[organisms==organism]\n",
    "    e_nnz_o = e_nnz[organisms==organism]\n",
    "    e_sum_o = e_sum[organisms==organism]    \n",
    "    e_sqsum_o = e_sqsum[organisms==organism]        \n",
    "    n_cells_o = n_cells[organisms==organism]\n",
    "    \n",
    "    e_nnz_o = rollup_across_cell_type_descendants_array(e_nnz_o,cell_types_o)\n",
    "    e_sum_o = rollup_across_cell_type_descendants_array(e_sum_o,cell_types_o)  \n",
    "    e_sqsum_o = rollup_across_cell_type_descendants_array(e_sqsum_o,cell_types_o)  \n",
    "    \n",
    "    e_nnz_rollup[organisms==organism]=e_nnz_o\n",
    "    e_sum_rollup[organisms==organism]=e_sum_o\n",
    "    e_sqsum_rollup[organisms==organism]=e_sqsum_o \n",
    "    \n",
    "    i_range = np.arange(e_sum_o.shape[0])\n",
    "    for i in range(e_sum_o.shape[0]):\n",
    "        sum1 = e_sum_o[i][None,:].copy()\n",
    "        sumsq1 = e_sqsum_o[i][None,:].copy()\n",
    "        n1 = n_cells_o[i][None,:].copy()\n",
    "\n",
    "\n",
    "        pvals, effects = _run_ttest(sum1,sumsq1,n1,\n",
    "                   e_sum_o, e_sqsum_o, n_cells_o)\n",
    "        pvals[i] = np.nan\n",
    "        effects[i] = np.nan\n",
    "\n",
    "        res = _post_process_stats(\n",
    "            cell_types_o[i],\n",
    "            cell_types_o,\n",
    "            y_index.index.values,\n",
    "            pvals,\n",
    "            effects,\n",
    "            percentile=0.05\n",
    "        )\n",
    "        \n",
    "        res = pd.DataFrame(res).T\n",
    "        res['cell_type_ontology_term_id'] = cell_types_o[i]\n",
    "        res['organism_ontology_term_id'] = organism\n",
    "        res['gene_ontology_term_id'] = res.index\n",
    "        res = res.reset_index(drop=True)\n",
    "        res = res[res['effect_size'].notnull()]\n",
    "        res = res[res['effect_size']>0]        \n",
    "        all_results.append(res)\n",
    "        \n",
    "x_new,y_new = (e_nnz_rollup+e_sum_rollup).nonzero()\n",
    "\n",
    "r_x_index = pd.Series(index=x_index.values,data=x_index.index.values)\n",
    "r_y_index = pd.Series(index=y_index.values,data=y_index.index.values)\n",
    "\n",
    "y_r_new = r_y_index[y_new].values\n",
    "\n",
    "x_r_new = r_x_index[x_new].values\n",
    "\n",
    "new_index = pd.Index([i+(j,) for i,j in zip(x_r_new,y_r_new)])\n",
    "\n",
    "nnz_flat = e_nnz_rollup[x_new,y_new]\n",
    "sum_flat = e_sum_rollup[x_new,y_new]\n",
    "\n",
    "new_index = new_index.set_names(['organism_ontology_term_id','cell_type_ontology_term_id','gene_ontology_term_id'])\n",
    "new_expression_rollup = pd.DataFrame(index=new_index)\n",
    "\n",
    "new_expression_rollup['nnz']=nnz_flat\n",
    "new_expression_rollup['sum']=sum_flat\n",
    "\n",
    "new_expression_rollup=new_expression_rollup.reset_index()\n",
    "\n",
    "markers_df = pd.concat(all_results,axis=0)\n",
    "markers_df=markers_df[markers_df['p_value']<1e-5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a371c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "top_per_group = markers_df.groupby(['organism_ontology_term_id','cell_type_ontology_term_id']).apply(lambda x: x.nlargest(100, 'effect_size'))\n",
    "\n",
    "columns = ['organism_ontology_term_id','cell_type_ontology_term_id','gene_ontology_term_id']\n",
    "o_ct_genes = list(zip(*top_per_group[columns].values.T))\n",
    "\n",
    "\n",
    "filt1 = new_expression_rollup['cell_type_ontology_term_id'].isin(top_per_group['cell_type_ontology_term_id'].unique())\n",
    "\n",
    "filt2 = new_expression_rollup['gene_ontology_term_id'].isin(top_per_group['gene_ontology_term_id'].unique())\n",
    "\n",
    "filt = np.logical_and(filt1,filt2)\n",
    "\n",
    "new_expression_rollup = new_expression_rollup[filt]\n",
    "\n",
    "new_expression_rollup.index = pd.Index(list(zip(*new_expression_rollup[['organism_ontology_term_id','cell_type_ontology_term_id','gene_ontology_term_id']].values.T)))\n",
    "\n",
    "universe_cell_counts_df = universe_cell_counts_df.groupby(['organism_ontology_term_id','cell_type_ontology_term_id']).sum()['n_cells']\n",
    "\n",
    "gene_id_to_symbol={}\n",
    "all_genes = []\n",
    "for k in snapshot.primary_filter_dimensions['gene_terms']:\n",
    "    for i in snapshot.primary_filter_dimensions['gene_terms'][k]:\n",
    "        gene_id_to_symbol.update(i)\n",
    "        all_genes.append(list(i.keys())[0])\n",
    "\n",
    "gene_id_to_name = pd.read_csv('ensembl_gene_ids_to_descriptions.tsv.gz',sep='\\t')\n",
    "\n",
    "gene_id_to_name = gene_id_to_name.set_index('Ensembl GeneIDs')['Description'].to_dict()\n",
    "\n",
    "data={}\n",
    "for i in o_ct_genes:\n",
    "    o,ct,gene = i\n",
    "    \n",
    "    nnz = new_expression_rollup['nnz'][i]\n",
    "    s = new_expression_rollup['sum'][i]\n",
    "    n_cells = universe_cell_counts_df[(o,ct)]\n",
    "    \n",
    "    a = data.get(ct,[])\n",
    "    a.append({\n",
    "        'me': s/nnz if nnz > 0 else 0,\n",
    "        'pc': nnz/n_cells,\n",
    "        'symbol': gene_id_to_symbol[gene],\n",
    "        'name': gene_id_to_name.get(gene,gene_id_to_symbol[gene]),\n",
    "        'organism': organism_id_to_name[o]\n",
    "    })\n",
    "    data[ct]=a\n",
    "\n",
    "\n",
    "json.dump(data,open('allEnrichedGenes.json','w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c786ce0",
   "metadata": {},
   "source": [
    "## Generate canonical marker genes data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "021f8a5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cell_guide_data_pipeline_source_artifacts/asctb_tables/asct-b-vh-lymph-vasculature.csv.gz\n",
      "cell_guide_data_pipeline_source_artifacts/asctb_tables/asct-b-vh-eye.csv.gz\n",
      "cell_guide_data_pipeline_source_artifacts/asctb_tables/asct-b-vh-small-intestine.csv.gz\n",
      "cell_guide_data_pipeline_source_artifacts/asctb_tables/ASCT-B_VH_Lung.csv.gz\n",
      "cell_guide_data_pipeline_source_artifacts/asctb_tables/asct-b-vh-blood-pelvis.csv.gz\n",
      "cell_guide_data_pipeline_source_artifacts/asctb_tables/ASCT-B_VH_Skin.csv.gz\n",
      "Skipping\n",
      "cell_guide_data_pipeline_source_artifacts/asctb_tables/ASCT-B_VH_Fallopian_Tube.csv.gz\n",
      "cell_guide_data_pipeline_source_artifacts/asctb_tables/asct-b-vh-blood-vasculature.csv.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5p/qcznfv1105v6fnyht9qvdznr0000gp/T/ipykernel_2820/2445514966.py:132: DtypeWarning: Columns (36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,63,64,65) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file,skiprows=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cell_guide_data_pipeline_source_artifacts/asctb_tables/ASCT-B_VH_Prostate.csv.gz\n",
      "cell_guide_data_pipeline_source_artifacts/asctb_tables/asct-b-vh-ovary.csv.gz\n",
      "Skipping\n",
      "cell_guide_data_pipeline_source_artifacts/asctb_tables/ASCT-B_VH_Kidney.csv.gz\n",
      "cell_guide_data_pipeline_source_artifacts/asctb_tables/asct-b-vh-thymus.csv.gz\n",
      "cell_guide_data_pipeline_source_artifacts/asctb_tables/ASCT-B_VH_Uterus.csv.gz\n",
      "cell_guide_data_pipeline_source_artifacts/asctb_tables/asct-b-vh-pancreas.csv.gz\n",
      "cell_guide_data_pipeline_source_artifacts/asctb_tables/ASCT-B_VH_Urinary_Bladder.csv.gz\n",
      "cell_guide_data_pipeline_source_artifacts/asctb_tables/asct-b-vh-heart.csv.gz\n",
      "cell_guide_data_pipeline_source_artifacts/asctb_tables/asct-b-vh-large-intestine.csv.gz\n",
      "cell_guide_data_pipeline_source_artifacts/asctb_tables/asct-b-allen-brain.csv.gz\n",
      "cell_guide_data_pipeline_source_artifacts/asctb_tables/asct-b-vh-bonemarrow-pelvis.csv.gz\n",
      "cell_guide_data_pipeline_source_artifacts/asctb_tables/ASCT-B_VH_Placenta_Full_Term.csv.gz\n",
      "cell_guide_data_pipeline_source_artifacts/asctb_tables/ASCT-B_VH_Peripheral_Nervous_System.csv.gz\n",
      "cell_guide_data_pipeline_source_artifacts/asctb_tables/ASCT-B_VH_Liver.csv.gz\n",
      "cell_guide_data_pipeline_source_artifacts/asctb_tables/ASCT-B_VH_Ureter.csv.gz\n",
      "cell_guide_data_pipeline_source_artifacts/asctb_tables/ASCT-B_NIH_Lymph_Node.csv.gz\n",
      "cell_guide_data_pipeline_source_artifacts/asctb_tables/ASCT-B_VH_Knee.csv.gz\n",
      "Skipping\n",
      "cell_guide_data_pipeline_source_artifacts/asctb_tables/asct-b-vh-spleen.csv.gz\n"
     ]
    }
   ],
   "source": [
    "def get_all_prefix_cols(prefix, cols):\n",
    "    i=1\n",
    "    prefix_cols = []\n",
    "    while True:\n",
    "        col = f\"{prefix}{i}\"\n",
    "        if col in cols:\n",
    "            prefix_cols.append(col)\n",
    "            i+=1\n",
    "        elif col.upper() in cols:\n",
    "            prefix_cols.append(col.upper())\n",
    "            i+=1            \n",
    "        elif col.lower() in cols:\n",
    "            prefix_cols.append(col.lower())\n",
    "            i+=1\n",
    "        else:\n",
    "            break   \n",
    "    return prefix_cols\n",
    "\n",
    "def get_all_suffix_cols(prefix,suffix, cols):\n",
    "    i=1\n",
    "    suffix_cols = []\n",
    "    while True:\n",
    "        col = f\"{prefix}{i}{suffix}\"\n",
    "        if col in cols:\n",
    "            suffix_cols.append(col)\n",
    "            i+=1\n",
    "        elif col.upper() in cols:\n",
    "            suffix_cols.append(col.upper())\n",
    "            i+=1            \n",
    "        elif col.lower() in cols:\n",
    "            suffix_cols.append(col.lower())\n",
    "            i+=1\n",
    "        else:\n",
    "            break    \n",
    "    return suffix_cols\n",
    "\n",
    "def get_gene_name(gene):\n",
    "    a = requests.get(f\"https://api.cellxgene.dev.single-cell.czi.technology/gene_info/v1/gene_info?gene={gene}\")\n",
    "    if a.status_code == 200:\n",
    "        r = a.json()\n",
    "        return r['name']\n",
    "    else:\n",
    "        return gene\n",
    "    \n",
    "def try_delete(d, k):\n",
    "    try:\n",
    "        del d[k]\n",
    "    except:\n",
    "        try:\n",
    "            del d[k[0]+k[1:].lower()]\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "def get_title_and_citation_from_doi(doi):\n",
    "    url = f\"https://api.crossref.org/works/{doi}\"\n",
    "\n",
    "    # Send a GET request to the API\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # If the GET request is successful, the status code will be 200\n",
    "    if response.status_code == 200:\n",
    "        # Get the response data\n",
    "        data = response.json()\n",
    "\n",
    "        # Get the title and citation count from the data\n",
    "        try:\n",
    "            title = data['message']['title'][0]\n",
    "            citation = format_citation_mg(data['message'])\n",
    "        except:\n",
    "            try:\n",
    "                title = data['message']['items'][0]['title'][0]\n",
    "                citation = format_citation_mg(data['message']['items'][0])                \n",
    "            except:\n",
    "                return doi\n",
    "        return f\"{title}\\n\\n - {citation}\"\n",
    "    else:\n",
    "        return doi\n",
    "    \n",
    "def format_citation_mg(message):\n",
    "    first_author = message['author'][0]\n",
    "    if \"family\" in first_author:\n",
    "        author_str = f\"{first_author['family']}, {first_author['given']} et al.\"\n",
    "    else:\n",
    "        author_str = f\"{first_author['name']} et al.\"\n",
    "    \n",
    "    journal = message['container-title'][0]\n",
    "    year = message['created']['date-parts'][0][0]\n",
    "    \n",
    "    return f\"{author_str} ({year}) {journal}\"\n",
    "\n",
    "def get_tissue_name(t):\n",
    "    t=t.replace(':','_')\n",
    "    urls = [\n",
    "        f\"https://www.ebi.ac.uk/ols4/api/ontologies/clo/terms/http%253A%252F%252Fpurl.obolibrary.org%252Fobo%252F{t}\",\n",
    "        f\"https://www.ebi.ac.uk/ols4/api/ontologies/envo/terms/http%253A%252F%252Fpurl.obolibrary.org%252Fobo%252F{t}\",\n",
    "        f\"https://www.ebi.ac.uk/ols4/api/ontologies/flopo/terms/http%253A%252F%252Fpurl.obolibrary.org%252Fobo%252F{t}\",\n",
    "        f\"https://www.ebi.ac.uk/ols4/api/ontologies/doid/terms/http%253A%252F%252Fpurl.obolibrary.org%252Fobo%252F{t}\",\n",
    "    ]\n",
    "    for url in urls:    \n",
    "        response = requests.get(url)\n",
    "        if response.status_code==200:\n",
    "            r = response.json()\n",
    "            return r['label']\n",
    "    return t\n",
    "\n",
    "pf = json.load(open('prod-snapshot/primary_filter_dimensions.json','r'))\n",
    "all_human_genes = [list(i.values())[0] for i in pf['gene_terms']['NCBITaxon:9606']]\n",
    "\n",
    "X = tiledb.open('prod-snapshot/cell_counts/')\n",
    "cc = X.df[:]\n",
    "tissue_original = list(set(cc['tissue_original_ontology_term_id']))\n",
    "tissue = list(set(cc['tissue_ontology_term_id']))\n",
    "\n",
    "m = {}\n",
    "[m.update(i) for i in pf['tissue_terms']['NCBITaxon:9606']];\n",
    "for i in tissue:\n",
    "    if i not in m:\n",
    "        m[i]=i\n",
    "        \n",
    "for i in tissue_original:\n",
    "    if i not in m:\n",
    "        m[i]=i\n",
    "\n",
    "files = glob.glob('cell_guide_data_pipeline_source_artifacts/asctb_tables/*.csv.gz')\n",
    "\n",
    "parsed_table_entries = []\n",
    "\n",
    "seen=[]\n",
    "for file in files:\n",
    "    print(file)\n",
    "\n",
    "    df = pd.read_csv(file,skiprows=10)\n",
    "    assert df.columns[0]=='AS/1'\n",
    "\n",
    "    cols = list(df.columns)\n",
    "\n",
    "    ref_prefix = \"Ref/\"\n",
    "    ref_doi_suffix = \"/DOI\"\n",
    "\n",
    "    ref_prefixes = get_all_prefix_cols(ref_prefix,cols)\n",
    "    if len(ref_prefixes):\n",
    "        prefix=ref_prefixes[0].split('/')[0]+\"/\"\n",
    "        ref_suffixes=get_all_suffix_cols(prefix,ref_doi_suffix,cols)\n",
    "        ref_suffixes_notes=get_all_suffix_cols(prefix,\"/NOTES\",cols)\n",
    "    else:\n",
    "        ref_suffixes=[]\n",
    "        ref_suffixes_notes=[]\n",
    "\n",
    "\n",
    "    gene_prefix = \"BGene/\"\n",
    "    gene_label_suffix = \"/LABEL\"\n",
    "\n",
    "    gene_prefixes = get_all_prefix_cols(gene_prefix,cols)\n",
    "    if len(gene_prefixes):\n",
    "        prefix=gene_prefixes[0].split('/')[0]+\"/\"\n",
    "        gene_suffixes=get_all_suffix_cols(prefix,gene_label_suffix,cols)\n",
    "    else:\n",
    "        gene_suffixes=[]\n",
    "\n",
    "    tissue_prefix = \"AS/\"\n",
    "    protein_label_suffix = \"/ID\"\n",
    "\n",
    "    tissue_prefixes = get_all_prefix_cols(tissue_prefix,cols)\n",
    "    if len(tissue_prefixes):\n",
    "        prefix=tissue_prefixes[0].split('/')[0]+\"/\"\n",
    "        tissue_suffixes=get_all_suffix_cols(prefix,protein_label_suffix,cols) \n",
    "    else:\n",
    "        tissue_suffixes=[]\n",
    "\n",
    "    ct = \"CT/1\"\n",
    "    ctid = \"CT/1/ID\"\n",
    "    try:\n",
    "        assert len(ref_prefixes) > 0\n",
    "        assert len(ref_suffixes) > 0\n",
    "        assert len(gene_prefixes) > 0 \n",
    "        assert len(gene_suffixes) > 0 \n",
    "        assert len(tissue_suffixes) > 0\n",
    "    except:\n",
    "        print(\"Skipping\")\n",
    "        continue\n",
    "    \n",
    "    \n",
    "    for n in range(df.shape[0]):\n",
    "        res = df.iloc[n].to_dict()\n",
    "        data_tmp = {i: res[i] for i in res if i in [ct, ctid] + ref_prefixes+ref_suffixes+gene_prefixes+gene_suffixes+tissue_suffixes+ref_suffixes_notes}\n",
    "        data = data_tmp.copy()\n",
    "        genes = []\n",
    "        gene_to_key = {}\n",
    "        for i in gene_prefixes:\n",
    "            data_tmp[i] = str(data_tmp[i]).split(' ')[0]\n",
    "            if data_tmp[i].upper() not in all_human_genes or data_tmp[i]=='nan':\n",
    "                try_delete(data,i)\n",
    "                try_delete(data,i+'/LABEL')\n",
    "            else:\n",
    "                data[i] = data_tmp[i].upper()\n",
    "                genes.append(data[i])\n",
    "                gene_to_key[data[i]] = i\n",
    "\n",
    "        valid_ref_accessors = []\n",
    "        for i in ref_suffixes:\n",
    "            i_prefix = '/'.join(i.split('/')[:-1])\n",
    "            \n",
    "            if str(data[i_prefix +'/DOI'])=='nan' or str(data[i_prefix +'/DOI'])=='No DOI':\n",
    "                try_delete(data,i)\n",
    "                try_delete(data,i_prefix)\n",
    "                try_delete(data,i_prefix+'/NOTES')\n",
    "            else:\n",
    "                data[i_prefix+'/DOI'] = data[i_prefix+'/DOI'].split(' ')[-1]\n",
    "                try_delete(data,i_prefix)\n",
    "                try_delete(data,i_prefix+'/NOTES')                \n",
    "                valid_ref_accessors.append(i_prefix)\n",
    "\n",
    "        refs = []\n",
    "        titles = []\n",
    "        for i in valid_ref_accessors:\n",
    "            doi = data[i+'/DOI']\n",
    "            if doi != \"\":\n",
    "                if doi[-1] == \".\":\n",
    "                    doi = doi[:-1]\n",
    "\n",
    "            title = get_title_and_citation_from_doi(doi)\n",
    "            refs.append(doi)\n",
    "            titles.append(title)\n",
    "            \n",
    "        refs = ';;'.join(refs)\n",
    "        titles = ';;'.join(titles)\n",
    "            \n",
    "        if not str(data[ctid]).startswith('CL:'):         \n",
    "            continue\n",
    "        \n",
    "        tissue_general = None\n",
    "        for i in tissue_suffixes[::-1]:\n",
    "            if data[i] in tissue:\n",
    "                tissue_general = data[i]\n",
    "                break\n",
    "\n",
    "        tissue_specific = None\n",
    "        for i in tissue_suffixes[::-1]:\n",
    "            if data[i] in tissue_original:\n",
    "                tissue_specific = data[i]\n",
    "                break\n",
    "\n",
    "        if tissue_general is None:\n",
    "            for i in tissue_suffixes:\n",
    "                if data[i].startswith(\"UBERON:\"):\n",
    "                    tissue_general=data[i]\n",
    "                    break\n",
    "                    \n",
    "        if tissue_specific is None:\n",
    "            for i in tissue_suffixes:\n",
    "                if data[i].startswith(\"UBERON:\"):\n",
    "                    tissue_specific=data[i]                    \n",
    "                    break\n",
    "                    \n",
    "        assert tissue_general is not None\n",
    "        assert tissue_specific is not None\n",
    "\n",
    "        for gene in genes:\n",
    "            label = str(data[gene_to_key[gene]+'/LABEL'])\n",
    "            if gene == label.upper() or label == 'nan':\n",
    "                label = get_gene_name(gene)\n",
    "\n",
    "\n",
    "            gene_dict = {\n",
    "                \"tissue_general\": tissue_general,\n",
    "                \"tissue_specific\": tissue_specific,\n",
    "                \"symbol\": gene,\n",
    "                \"name\": label,\n",
    "                \"publication\": refs,\n",
    "                \"publication_titles\": titles,\n",
    "                \"cell_type_ontology_term_id\": data[ctid]\n",
    "            }\n",
    "            hashed_dict = hash(json.dumps(gene_dict))\n",
    "            if hashed_dict not in seen:\n",
    "                parsed_table_entries.append(gene_dict)\n",
    "                seen.append(hashed_dict)\n",
    "                \n",
    "\n",
    "ts = list(set([i['tissue_general'] for i in parsed_table_entries]+[i['tissue_specific'] for i in parsed_table_entries]))\n",
    "\n",
    "tissues_by_id = {t: get_tissue_name(t) for t in ts}\n",
    "\n",
    "gene_infos = {}\n",
    "for entry in parsed_table_entries:\n",
    "    entry = entry.copy()\n",
    "    ct = entry['cell_type_ontology_term_id']\n",
    "    del entry['cell_type_ontology_term_id']\n",
    "    \n",
    "    a = gene_infos.get(ct,[])\n",
    "    entry['tissue_general'] = tissues_by_id.get(entry['tissue_general'],entry['tissue_general'])\n",
    "    entry['tissue_specific'] =tissues_by_id.get(entry['tissue_specific'],entry['tissue_specific'])\n",
    "    a.append(entry)\n",
    "    gene_infos[ct]=a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c79a2f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func1(x):\n",
    "    y = [y for y in x.values if y != '']\n",
    "    z = []\n",
    "    for i in y:\n",
    "        if i not in z:\n",
    "            z.append(i)\n",
    "    res = ';;'.join(z)\n",
    "    return res\n",
    "\n",
    "def func2(x):\n",
    "    res = x.values\n",
    "    res2=[i not in gi2['symbol'].values for i in res]\n",
    "    index = 0\n",
    "    try:\n",
    "        index = res2.index(True)\n",
    "    except:\n",
    "        pass\n",
    "    return res[index]\n",
    "\n",
    "for key in gene_infos:\n",
    "    gi = pd.DataFrame(gene_infos[key])\n",
    "    gi2 = pd.DataFrame(gi)\n",
    "    \n",
    "    gi = gi.groupby([\"tissue_general\",\"symbol\"]).agg({'name': func2,'publication': func1, 'publication_titles': func1}).reset_index().to_dict(orient=\"records\")\n",
    "    \n",
    "    gi2 = pd.DataFrame(gi)\n",
    "    gi2['n']=1\n",
    "    gi3 = gi2.groupby(['symbol','tissue_general']).sum(numeric_only=True)['n']\n",
    "    valid_genes = list(set(gi3.index[gi3>0].get_level_values('symbol')))\n",
    "    gi2 = pd.DataFrame(gi)\n",
    "\n",
    "    gi2 = gi2[gi2['symbol'].isin(valid_genes)]\n",
    "    gi3 = gi2.groupby('symbol').agg({'name': func2,'publication': func1, 'publication_titles': func1})\n",
    "    gi3 = gi3.reset_index()\n",
    "    gi3['tissue_general']='All Tissues'\n",
    "    gi3['tissue_specific']='All Tissues'\n",
    "    gi3 = gi3[gi2.columns]\n",
    "    gi.extend(gi3.to_dict(orient=\"records\"))\n",
    "    gene_infos[key]=gi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9cd87db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(gene_infos,open('frontend/src/views/CellCards/common/fixtures/allCellTypeMarkerGenes.json','w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a5f800",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6440d304",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3c74dc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sparse import GCXS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e49952fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tissue_ontology_term_id</th>\n",
       "      <th>organism_ontology_term_id</th>\n",
       "      <th>cell_type_ontology_term_id</th>\n",
       "      <th>tissue_original_ontology_term_id</th>\n",
       "      <th>dataset_id</th>\n",
       "      <th>assay_ontology_term_id</th>\n",
       "      <th>development_stage_ontology_term_id</th>\n",
       "      <th>disease_ontology_term_id</th>\n",
       "      <th>self_reported_ethnicity_ontology_term_id</th>\n",
       "      <th>sex_ontology_term_id</th>\n",
       "      <th>n_cells</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CL:0000082 (cell culture)</td>\n",
       "      <td>NCBITaxon:9606</td>\n",
       "      <td>CL:0000010</td>\n",
       "      <td>CL:0000082 (cell culture)</td>\n",
       "      <td>4b9e0a15-c006-45d9-860f-b8a43ccf7d9d</td>\n",
       "      <td>EFO:0008722</td>\n",
       "      <td>unknown</td>\n",
       "      <td>PATO:0000461</td>\n",
       "      <td>unknown</td>\n",
       "      <td>PATO:0000384</td>\n",
       "      <td>16512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CL:0000082 (cell culture)</td>\n",
       "      <td>NCBITaxon:9606</td>\n",
       "      <td>CL:0000010</td>\n",
       "      <td>CL:0000082 (cell culture)</td>\n",
       "      <td>ca421096-6240-4cee-8c12-d20899b3e005</td>\n",
       "      <td>EFO:0008722</td>\n",
       "      <td>unknown</td>\n",
       "      <td>MONDO:0100096</td>\n",
       "      <td>unknown</td>\n",
       "      <td>PATO:0000384</td>\n",
       "      <td>30287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CL:0000082 (cell culture)</td>\n",
       "      <td>NCBITaxon:9606</td>\n",
       "      <td>CL:0000010</td>\n",
       "      <td>CL:0000082 (cell culture)</td>\n",
       "      <td>ca421096-6240-4cee-8c12-d20899b3e005</td>\n",
       "      <td>EFO:0008722</td>\n",
       "      <td>unknown</td>\n",
       "      <td>PATO:0000461</td>\n",
       "      <td>unknown</td>\n",
       "      <td>PATO:0000384</td>\n",
       "      <td>16218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CL:0000082 (cell culture)</td>\n",
       "      <td>NCBITaxon:9606</td>\n",
       "      <td>CL:0000010</td>\n",
       "      <td>CL:0000082 (cell culture)</td>\n",
       "      <td>4b9e0a15-c006-45d9-860f-b8a43ccf7d9d</td>\n",
       "      <td>EFO:0008722</td>\n",
       "      <td>unknown</td>\n",
       "      <td>MONDO:0005091</td>\n",
       "      <td>unknown</td>\n",
       "      <td>PATO:0000384</td>\n",
       "      <td>16135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CL:0000082 (cell culture)</td>\n",
       "      <td>NCBITaxon:9606</td>\n",
       "      <td>CL:0000010</td>\n",
       "      <td>CL:0000082 (cell culture)</td>\n",
       "      <td>4b9e0a15-c006-45d9-860f-b8a43ccf7d9d</td>\n",
       "      <td>EFO:0008722</td>\n",
       "      <td>unknown</td>\n",
       "      <td>MONDO:0100096</td>\n",
       "      <td>unknown</td>\n",
       "      <td>PATO:0000384</td>\n",
       "      <td>16243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37498</th>\n",
       "      <td>UBERON:0018707</td>\n",
       "      <td>NCBITaxon:9606</td>\n",
       "      <td>CL:0000786</td>\n",
       "      <td>UBERON:0018707</td>\n",
       "      <td>53d208b0-2cfd-4366-9866-c3c6114081bc</td>\n",
       "      <td>EFO:0009922</td>\n",
       "      <td>HsapDv:0000155</td>\n",
       "      <td>PATO:0000461</td>\n",
       "      <td>HANCESTRO:0016</td>\n",
       "      <td>PATO:0000383</td>\n",
       "      <td>453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37499</th>\n",
       "      <td>UBERON:0035210</td>\n",
       "      <td>NCBITaxon:9606</td>\n",
       "      <td>CL:0000115</td>\n",
       "      <td>UBERON:0035210</td>\n",
       "      <td>b252b015-b488-4d5c-b16e-968c13e48a2c</td>\n",
       "      <td>EFO:0009922</td>\n",
       "      <td>HsapDv:0000150</td>\n",
       "      <td>MONDO:0024885</td>\n",
       "      <td>HANCESTRO:0005</td>\n",
       "      <td>PATO:0000383</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37500</th>\n",
       "      <td>UBERON:0035210</td>\n",
       "      <td>NCBITaxon:9606</td>\n",
       "      <td>CL:4030006</td>\n",
       "      <td>UBERON:0035210</td>\n",
       "      <td>b252b015-b488-4d5c-b16e-968c13e48a2c</td>\n",
       "      <td>EFO:0009922</td>\n",
       "      <td>HsapDv:0000150</td>\n",
       "      <td>MONDO:0024885</td>\n",
       "      <td>HANCESTRO:0005</td>\n",
       "      <td>PATO:0000383</td>\n",
       "      <td>293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37501</th>\n",
       "      <td>UBERON:0035210</td>\n",
       "      <td>NCBITaxon:9606</td>\n",
       "      <td>CL:0000576</td>\n",
       "      <td>UBERON:0035210</td>\n",
       "      <td>b252b015-b488-4d5c-b16e-968c13e48a2c</td>\n",
       "      <td>EFO:0009922</td>\n",
       "      <td>HsapDv:0000150</td>\n",
       "      <td>MONDO:0024885</td>\n",
       "      <td>HANCESTRO:0005</td>\n",
       "      <td>PATO:0000383</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37502</th>\n",
       "      <td>UBERON:0035210</td>\n",
       "      <td>NCBITaxon:9606</td>\n",
       "      <td>CL:0000057</td>\n",
       "      <td>UBERON:0035210</td>\n",
       "      <td>b252b015-b488-4d5c-b16e-968c13e48a2c</td>\n",
       "      <td>EFO:0009922</td>\n",
       "      <td>HsapDv:0000150</td>\n",
       "      <td>MONDO:0024885</td>\n",
       "      <td>HANCESTRO:0005</td>\n",
       "      <td>PATO:0000383</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37503 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         tissue_ontology_term_id organism_ontology_term_id  \\\n",
       "0      CL:0000082 (cell culture)            NCBITaxon:9606   \n",
       "1      CL:0000082 (cell culture)            NCBITaxon:9606   \n",
       "2      CL:0000082 (cell culture)            NCBITaxon:9606   \n",
       "3      CL:0000082 (cell culture)            NCBITaxon:9606   \n",
       "4      CL:0000082 (cell culture)            NCBITaxon:9606   \n",
       "...                          ...                       ...   \n",
       "37498             UBERON:0018707            NCBITaxon:9606   \n",
       "37499             UBERON:0035210            NCBITaxon:9606   \n",
       "37500             UBERON:0035210            NCBITaxon:9606   \n",
       "37501             UBERON:0035210            NCBITaxon:9606   \n",
       "37502             UBERON:0035210            NCBITaxon:9606   \n",
       "\n",
       "      cell_type_ontology_term_id tissue_original_ontology_term_id  \\\n",
       "0                     CL:0000010        CL:0000082 (cell culture)   \n",
       "1                     CL:0000010        CL:0000082 (cell culture)   \n",
       "2                     CL:0000010        CL:0000082 (cell culture)   \n",
       "3                     CL:0000010        CL:0000082 (cell culture)   \n",
       "4                     CL:0000010        CL:0000082 (cell culture)   \n",
       "...                          ...                              ...   \n",
       "37498                 CL:0000786                   UBERON:0018707   \n",
       "37499                 CL:0000115                   UBERON:0035210   \n",
       "37500                 CL:4030006                   UBERON:0035210   \n",
       "37501                 CL:0000576                   UBERON:0035210   \n",
       "37502                 CL:0000057                   UBERON:0035210   \n",
       "\n",
       "                                 dataset_id assay_ontology_term_id  \\\n",
       "0      4b9e0a15-c006-45d9-860f-b8a43ccf7d9d            EFO:0008722   \n",
       "1      ca421096-6240-4cee-8c12-d20899b3e005            EFO:0008722   \n",
       "2      ca421096-6240-4cee-8c12-d20899b3e005            EFO:0008722   \n",
       "3      4b9e0a15-c006-45d9-860f-b8a43ccf7d9d            EFO:0008722   \n",
       "4      4b9e0a15-c006-45d9-860f-b8a43ccf7d9d            EFO:0008722   \n",
       "...                                     ...                    ...   \n",
       "37498  53d208b0-2cfd-4366-9866-c3c6114081bc            EFO:0009922   \n",
       "37499  b252b015-b488-4d5c-b16e-968c13e48a2c            EFO:0009922   \n",
       "37500  b252b015-b488-4d5c-b16e-968c13e48a2c            EFO:0009922   \n",
       "37501  b252b015-b488-4d5c-b16e-968c13e48a2c            EFO:0009922   \n",
       "37502  b252b015-b488-4d5c-b16e-968c13e48a2c            EFO:0009922   \n",
       "\n",
       "      development_stage_ontology_term_id disease_ontology_term_id  \\\n",
       "0                                unknown             PATO:0000461   \n",
       "1                                unknown            MONDO:0100096   \n",
       "2                                unknown             PATO:0000461   \n",
       "3                                unknown            MONDO:0005091   \n",
       "4                                unknown            MONDO:0100096   \n",
       "...                                  ...                      ...   \n",
       "37498                     HsapDv:0000155             PATO:0000461   \n",
       "37499                     HsapDv:0000150            MONDO:0024885   \n",
       "37500                     HsapDv:0000150            MONDO:0024885   \n",
       "37501                     HsapDv:0000150            MONDO:0024885   \n",
       "37502                     HsapDv:0000150            MONDO:0024885   \n",
       "\n",
       "      self_reported_ethnicity_ontology_term_id sex_ontology_term_id  n_cells  \n",
       "0                                      unknown         PATO:0000384    16512  \n",
       "1                                      unknown         PATO:0000384    30287  \n",
       "2                                      unknown         PATO:0000384    16218  \n",
       "3                                      unknown         PATO:0000384    16135  \n",
       "4                                      unknown         PATO:0000384    16243  \n",
       "...                                        ...                  ...      ...  \n",
       "37498                           HANCESTRO:0016         PATO:0000383      453  \n",
       "37499                           HANCESTRO:0005         PATO:0000383       15  \n",
       "37500                           HANCESTRO:0005         PATO:0000383      293  \n",
       "37501                           HANCESTRO:0005         PATO:0000383       59  \n",
       "37502                           HANCESTRO:0005         PATO:0000383      105  \n",
       "\n",
       "[37503 rows x 11 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "9aae3df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "GCXS??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "f9924667",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.random.randint(0,2,(100,20,40))\n",
    "z = GCXS.from_numpy(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "5be97677",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tbody><tr><th style=\"text-align: left\">Format</th><td style=\"text-align: left\">gcxs</td></tr><tr><th style=\"text-align: left\">Data Type</th><td style=\"text-align: left\">int64</td></tr><tr><th style=\"text-align: left\">Shape</th><td style=\"text-align: left\">(100, 20, 40)</td></tr><tr><th style=\"text-align: left\">nnz</th><td style=\"text-align: left\">40049</td></tr><tr><th style=\"text-align: left\">Density</th><td style=\"text-align: left\">0.5006125</td></tr><tr><th style=\"text-align: left\">Read-only</th><td style=\"text-align: left\">True</td></tr><tr><th style=\"text-align: left\">Size</th><td style=\"text-align: left\">625.9K</td></tr><tr><th style=\"text-align: left\">Storage ratio</th><td style=\"text-align: left\">1.0</td></tr><tr><th style=\"text-align: left\">Compressed Axes</th><td style=\"text-align: left\">(1,)</td></tr></tbody></table>"
      ],
      "text/plain": [
       "<GCXS: shape=(100, 20, 40), dtype=int64, nnz=40049, fill_value=0, compressed_axes=(1,)>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "7c5d7edf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.08"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "16*130e6/1e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "08253df1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.004194861294913"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.nbytes/40049"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "ea4222b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80000"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "0dee4eb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0,  1968,  3935,  6001,  8000,  9940, 11962, 13986, 16009,\n",
       "       17974, 19974, 21966, 24014, 25997, 28001, 29971, 31994, 33993,\n",
       "       35966, 38014, 40049])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.indptr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "71c53423",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T',\n",
       " '_2d_transpose',\n",
       " '__abs__',\n",
       " '__add__',\n",
       " '__and__',\n",
       " '__array__',\n",
       " '__array_function__',\n",
       " '__array_priority__',\n",
       " '__array_ufunc__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__divmod__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__floordiv__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__iadd__',\n",
       " '__iand__',\n",
       " '__ifloordiv__',\n",
       " '__ilshift__',\n",
       " '__imatmul__',\n",
       " '__imod__',\n",
       " '__imul__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__invert__',\n",
       " '__ior__',\n",
       " '__ipow__',\n",
       " '__irshift__',\n",
       " '__isub__',\n",
       " '__itruediv__',\n",
       " '__ixor__',\n",
       " '__le__',\n",
       " '__lshift__',\n",
       " '__lt__',\n",
       " '__matmul__',\n",
       " '__metaclass__',\n",
       " '__mod__',\n",
       " '__module__',\n",
       " '__mul__',\n",
       " '__ne__',\n",
       " '__neg__',\n",
       " '__new__',\n",
       " '__or__',\n",
       " '__pos__',\n",
       " '__pow__',\n",
       " '__radd__',\n",
       " '__rand__',\n",
       " '__rdivmod__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__rfloordiv__',\n",
       " '__rlshift__',\n",
       " '__rmatmul__',\n",
       " '__rmod__',\n",
       " '__rmul__',\n",
       " '__ror__',\n",
       " '__rpow__',\n",
       " '__rrshift__',\n",
       " '__rshift__',\n",
       " '__rsub__',\n",
       " '__rtruediv__',\n",
       " '__rxor__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__sub__',\n",
       " '__subclasshook__',\n",
       " '__truediv__',\n",
       " '__weakref__',\n",
       " '__xor__',\n",
       " '_axis_order',\n",
       " '_axisptr',\n",
       " '_compressed_axes',\n",
       " '_compressed_shape',\n",
       " '_make_shallow_copy_of',\n",
       " '_prune',\n",
       " '_reduce',\n",
       " '_reduce_calc',\n",
       " '_reduce_return',\n",
       " '_reordered_shape',\n",
       " '_repr_html_',\n",
       " 'all',\n",
       " 'amax',\n",
       " 'amin',\n",
       " 'any',\n",
       " 'asformat',\n",
       " 'astype',\n",
       " 'change_compressed_axes',\n",
       " 'clip',\n",
       " 'compressed_axes',\n",
       " 'conj',\n",
       " 'copy',\n",
       " 'data',\n",
       " 'density',\n",
       " 'dot',\n",
       " 'dtype',\n",
       " 'fill_value',\n",
       " 'flatten',\n",
       " 'format',\n",
       " 'from_coo',\n",
       " 'from_iter',\n",
       " 'from_numpy',\n",
       " 'from_scipy_sparse',\n",
       " 'imag',\n",
       " 'indices',\n",
       " 'indptr',\n",
       " 'max',\n",
       " 'maybe_densify',\n",
       " 'mean',\n",
       " 'min',\n",
       " 'nbytes',\n",
       " 'ndim',\n",
       " 'nnz',\n",
       " 'prod',\n",
       " 'real',\n",
       " 'reduce',\n",
       " 'reshape',\n",
       " 'round',\n",
       " 'round_',\n",
       " 'shape',\n",
       " 'size',\n",
       " 'std',\n",
       " 'sum',\n",
       " 'to_scipy_sparse',\n",
       " 'tocoo',\n",
       " 'todense',\n",
       " 'todok',\n",
       " 'transpose',\n",
       " 'var']"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "5ee8c400",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "de9481ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tbody><tr><th style=\"text-align: left\">Format</th><td style=\"text-align: left\">gcxs</td></tr><tr><th style=\"text-align: left\">Data Type</th><td style=\"text-align: left\">float64</td></tr><tr><th style=\"text-align: left\">Shape</th><td style=\"text-align: left\">(2, 3, 2)</td></tr><tr><th style=\"text-align: left\">nnz</th><td style=\"text-align: left\">12</td></tr><tr><th style=\"text-align: left\">Density</th><td style=\"text-align: left\">1.0</td></tr><tr><th style=\"text-align: left\">Read-only</th><td style=\"text-align: left\">True</td></tr><tr><th style=\"text-align: left\">Size</th><td style=\"text-align: left\">216</td></tr><tr><th style=\"text-align: left\">Storage ratio</th><td style=\"text-align: left\">2.2</td></tr><tr><th style=\"text-align: left\">Compressed Axes</th><td style=\"text-align: left\">(0,)</td></tr></tbody></table>"
      ],
      "text/plain": [
       "<GCXS: shape=(2, 3, 2), dtype=float64, nnz=12, fill_value=0.0, compressed_axes=(0,)>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z[[1,4],[1,2,3],[0,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f5bfd496",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "shape mismatch: indexing arrays could not be broadcast together with shapes (2,) (3,) (2,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[96], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39msum()\n",
      "\u001b[0;31mIndexError\u001b[0m: shape mismatch: indexing arrays could not be broadcast together with shapes (2,) (3,) (2,) "
     ]
    }
   ],
   "source": [
    "x[[1,4],[1,2,3],[0,1]].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab74f851",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb30b89d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8de78206",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc = snapshot.cell_counts_cube.df[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1fe437e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "es = snapshot.expression_summary_cube"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9867d8ee",
   "metadata": {},
   "source": [
    "Notes:\n",
    "\n",
    "ZstdFilter level 22 --> Performance loss, don't want to go beyond 19\n",
    "\n",
    "we can remove assay, development\n",
    "\n",
    "Update schema to use dictionary filter?\n",
    "nnz = uint32\n",
    "\n",
    "\n",
    "Sparse n-dimensional cubes - \"sparse fiber data structure\"\n",
    "combine with fast minimum-perfect hash to turn a given string into a 0-n offset\n",
    "\"3 sex ids --> 0, 1, 2\"\n",
    "pd.Series(index=key,data=range) (slow version, but maybe good enough)\n",
    "index into sparse hypercube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fdcd4d02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><th>Domain</th></tr><tr><td><table><tr><th>Name</th><th>Domain</th><th>Tile</th><th>Data Type</th><th>Is Var-length</th><th>Filters</th></tr><tr><td>gene_ontology_term_id</td><td>('', '')</td><td>None</td><td>|S0</td><td>True</td><td><section>\n",
       "<table>\n",
       "<tr>\n",
       "<th>Name</th>\n",
       "<th>Option</th>\n",
       "<th>Level</th>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>ZstdFilter</td>\n",
       "<td>level</td><td>22</td></tr>\n",
       "</table>\n",
       "</section>\n",
       "</td></tr><tr><td>tissue_ontology_term_id</td><td>('', '')</td><td>None</td><td>|S0</td><td>True</td><td><section>\n",
       "<table>\n",
       "<tr>\n",
       "<th>Name</th>\n",
       "<th>Option</th>\n",
       "<th>Level</th>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>ZstdFilter</td>\n",
       "<td>level</td><td>22</td></tr>\n",
       "</table>\n",
       "</section>\n",
       "</td></tr><tr><td>organism_ontology_term_id</td><td>('', '')</td><td>None</td><td>|S0</td><td>True</td><td><section>\n",
       "<table>\n",
       "<tr>\n",
       "<th>Name</th>\n",
       "<th>Option</th>\n",
       "<th>Level</th>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>ZstdFilter</td>\n",
       "<td>level</td><td>22</td></tr>\n",
       "</table>\n",
       "</section>\n",
       "</td></tr></table></td></tr><tr><th>Attributes</th></tr><tr><td><table><tr><th>Name</th><th>Data Type</th><th>Is Var-Len</th><th>Is Nullable</th><th>Filters</th></tr><tr><td>cell_type_ontology_term_id</td><td>ascii</td><td>True</td><td>False</td><td><section>\n",
       "<table>\n",
       "<tr>\n",
       "<th>Name</th>\n",
       "<th>Option</th>\n",
       "<th>Level</th>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>ZstdFilter</td>\n",
       "<td>level</td><td>22</td></tr>\n",
       "</table>\n",
       "</section>\n",
       "</td></tr><tr><td>tissue_original_ontology_term_id</td><td>ascii</td><td>True</td><td>False</td><td><section>\n",
       "<table>\n",
       "<tr>\n",
       "<th>Name</th>\n",
       "<th>Option</th>\n",
       "<th>Level</th>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>ZstdFilter</td>\n",
       "<td>level</td><td>22</td></tr>\n",
       "</table>\n",
       "</section>\n",
       "</td></tr><tr><td>dataset_id</td><td>ascii</td><td>True</td><td>False</td><td><section>\n",
       "<table>\n",
       "<tr>\n",
       "<th>Name</th>\n",
       "<th>Option</th>\n",
       "<th>Level</th>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>ZstdFilter</td>\n",
       "<td>level</td><td>22</td></tr>\n",
       "</table>\n",
       "</section>\n",
       "</td></tr><tr><td>assay_ontology_term_id</td><td>ascii</td><td>True</td><td>False</td><td><section>\n",
       "<table>\n",
       "<tr>\n",
       "<th>Name</th>\n",
       "<th>Option</th>\n",
       "<th>Level</th>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>ZstdFilter</td>\n",
       "<td>level</td><td>22</td></tr>\n",
       "</table>\n",
       "</section>\n",
       "</td></tr><tr><td>development_stage_ontology_term_id</td><td>ascii</td><td>True</td><td>False</td><td><section>\n",
       "<table>\n",
       "<tr>\n",
       "<th>Name</th>\n",
       "<th>Option</th>\n",
       "<th>Level</th>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>ZstdFilter</td>\n",
       "<td>level</td><td>22</td></tr>\n",
       "</table>\n",
       "</section>\n",
       "</td></tr><tr><td>disease_ontology_term_id</td><td>ascii</td><td>True</td><td>False</td><td><section>\n",
       "<table>\n",
       "<tr>\n",
       "<th>Name</th>\n",
       "<th>Option</th>\n",
       "<th>Level</th>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>ZstdFilter</td>\n",
       "<td>level</td><td>22</td></tr>\n",
       "</table>\n",
       "</section>\n",
       "</td></tr><tr><td>self_reported_ethnicity_ontology_term_id</td><td>ascii</td><td>True</td><td>False</td><td><section>\n",
       "<table>\n",
       "<tr>\n",
       "<th>Name</th>\n",
       "<th>Option</th>\n",
       "<th>Level</th>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>ZstdFilter</td>\n",
       "<td>level</td><td>22</td></tr>\n",
       "</table>\n",
       "</section>\n",
       "</td></tr><tr><td>sex_ontology_term_id</td><td>ascii</td><td>True</td><td>False</td><td><section>\n",
       "<table>\n",
       "<tr>\n",
       "<th>Name</th>\n",
       "<th>Option</th>\n",
       "<th>Level</th>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>ZstdFilter</td>\n",
       "<td>level</td><td>22</td></tr>\n",
       "</table>\n",
       "</section>\n",
       "</td></tr><tr><td>nnz</td><td>uint64</td><td>False</td><td>False</td><td><section>\n",
       "<table>\n",
       "<tr>\n",
       "<th>Name</th>\n",
       "<th>Option</th>\n",
       "<th>Level</th>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>ZstdFilter</td>\n",
       "<td>level</td><td>22</td></tr>\n",
       "</table>\n",
       "</section>\n",
       "</td></tr><tr><td>sum</td><td>float32</td><td>False</td><td>False</td><td><section>\n",
       "<table>\n",
       "<tr>\n",
       "<th>Name</th>\n",
       "<th>Option</th>\n",
       "<th>Level</th>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>ZstdFilter</td>\n",
       "<td>level</td><td>22</td></tr>\n",
       "</table>\n",
       "</section>\n",
       "</td></tr></table></td></tr><tr><th>Cell Order</th></tr><tr><td>row-major</td></tr><tr><th>Tile Order</th></tr><tr><td>row-major</td></tr><tr><th>Capacity</th></tr><tr><td>10000</td></tr><tr><th>Sparse</th></tr><tr><td>True</td></tr><tr><th>Allows DuplicatesK/th></tr><tr><td>True</td></tr></table>"
      ],
      "text/plain": [
       "ArraySchema(\n",
       "  domain=Domain(*[\n",
       "    Dim(name='gene_ontology_term_id', domain=('', ''), tile=None, dtype='|S0', var=True, filters=FilterList([ZstdFilter(level=22), ])),\n",
       "    Dim(name='tissue_ontology_term_id', domain=('', ''), tile=None, dtype='|S0', var=True, filters=FilterList([ZstdFilter(level=22), ])),\n",
       "    Dim(name='organism_ontology_term_id', domain=('', ''), tile=None, dtype='|S0', var=True, filters=FilterList([ZstdFilter(level=22), ])),\n",
       "  ]),\n",
       "  attrs=[\n",
       "    Attr(name='cell_type_ontology_term_id', dtype='ascii', var=True, nullable=False, filters=FilterList([ZstdFilter(level=22), ])),\n",
       "    Attr(name='tissue_original_ontology_term_id', dtype='ascii', var=True, nullable=False, filters=FilterList([ZstdFilter(level=22), ])),\n",
       "    Attr(name='dataset_id', dtype='ascii', var=True, nullable=False, filters=FilterList([ZstdFilter(level=22), ])),\n",
       "    Attr(name='assay_ontology_term_id', dtype='ascii', var=True, nullable=False, filters=FilterList([ZstdFilter(level=22), ])),\n",
       "    Attr(name='development_stage_ontology_term_id', dtype='ascii', var=True, nullable=False, filters=FilterList([ZstdFilter(level=22), ])),\n",
       "    Attr(name='disease_ontology_term_id', dtype='ascii', var=True, nullable=False, filters=FilterList([ZstdFilter(level=22), ])),\n",
       "    Attr(name='self_reported_ethnicity_ontology_term_id', dtype='ascii', var=True, nullable=False, filters=FilterList([ZstdFilter(level=22), ])),\n",
       "    Attr(name='sex_ontology_term_id', dtype='ascii', var=True, nullable=False, filters=FilterList([ZstdFilter(level=22), ])),\n",
       "    Attr(name='nnz', dtype='uint64', var=False, nullable=False, filters=FilterList([ZstdFilter(level=22), ])),\n",
       "    Attr(name='sum', dtype='float32', var=False, nullable=False, filters=FilterList([ZstdFilter(level=22), ])),\n",
       "  ],\n",
       "  cell_order='row-major',\n",
       "  tile_order='row-major',\n",
       "  capacity=10000,\n",
       "  sparse=True,\n",
       "  allows_duplicates=True,\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac4603b",
   "metadata": {},
   "outputs": [],
   "source": [
    "es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a95b304",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = snapshot.expression_summary_cube.df[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e0a09f2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.037974336"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1037974336/1e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "497bba0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'|O'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['dataset_id'].dtype.str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3532bb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "eb5eddf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1649547.5"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sum'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2f0b3b86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index                                              128\n",
       "gene_ontology_term_id                       1037974336\n",
       "tissue_ontology_term_id                     1037974336\n",
       "organism_ontology_term_id                   1037974336\n",
       "cell_type_ontology_term_id                  1037974336\n",
       "tissue_original_ontology_term_id            1037974336\n",
       "dataset_id                                  1037974336\n",
       "assay_ontology_term_id                      1037974336\n",
       "development_stage_ontology_term_id          1037974336\n",
       "disease_ontology_term_id                    1037974336\n",
       "self_reported_ethnicity_ontology_term_id    1037974336\n",
       "sex_ontology_term_id                        1037974336\n",
       "nnz                                         1037974336\n",
       "sum                                          518987168\n",
       "dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.memory_usage()a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1090c826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gene_ontology_term_id\n",
      "tissue_ontology_term_id\n",
      "organism_ontology_term_id\n",
      "cell_type_ontology_term_id\n",
      "tissue_original_ontology_term_id\n",
      "dataset_id\n",
      "assay_ontology_term_id\n",
      "development_stage_ontology_term_id\n",
      "disease_ontology_term_id\n",
      "self_reported_ethnicity_ontology_term_id\n",
      "sex_ontology_term_id\n"
     ]
    }
   ],
   "source": [
    "for col in df:\n",
    "    if df[col].dtype.str == '|O':\n",
    "        print(col)\n",
    "        df2[col] = pd.Categorical(df[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e4f65d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['sum'] = df['sum'].astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c983a7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7872ecd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df2.groupby([\n",
    "    'gene_ontology_term_id',\n",
    "'tissue_ontology_term_id',\n",
    "'organism_ontology_term_id',\n",
    "'cell_type_ontology_term_id',\n",
    "'dataset_id',\n",
    "'disease_ontology_term_id',\n",
    "'self_reported_ethnicity_ontology_term_id',\n",
    "'sex_ontology_term_id'\n",
    "]).sum(numeric_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e2650597",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.129746792"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.shape[0]/1e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0d3bd509",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.376255544"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.memory_usage().sum()/1e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9aa8010d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ENSG00000000003', 'ENSG00000000003', 'ENSG00000000003', 'ENSG00000000003', 'ENSG00000000003', ..., 'ERCC-00171', 'ERCC-00171', 'ERCC-00171', 'ERCC-00171', 'ERCC-00171']\n",
       "Length: 129746792\n",
       "Categories (84025, object): ['ENSG00000000003', 'ENSG00000000005', 'ENSG00000000419', 'ENSG00000000457', ..., 'ERCC-00165', 'ERCC-00168', 'ERCC-00170', 'ERCC-00171']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Categorical(df['gene_ontology_term_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c1947b7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.974918100964429e-14"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df.shape[0]\n",
    "#np.prod(np.array([84025,62,4,571,199,305,15,186,36,15,3]).astype('float64'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
